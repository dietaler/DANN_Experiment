{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集的類別數：5\n",
      "類別標籤對應：{'Benign': 0, 'Botnets': 1, 'Brute-force': 2, 'DoS': 3, 'Web-attacks': 4}\n"
     ]
    }
   ],
   "source": [
    "# 定義圖像增強與標準化\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),  # 轉為 Tensor\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 資料集路徑\n",
    "train_data_dir = 'data/image/cicids2018/train_224/'\n",
    "val_data_dir = 'data/image/cicids2018/val_224/'\n",
    "batch_size = 128\n",
    "\n",
    "# 使用 ImageFolder 自動根據子資料夾讀取標籤\n",
    "train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform['train'])\n",
    "val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform['val'])\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# 檢查類別數量\n",
    "print(f\"訓練集的類別數：{len(train_dataset.classes)}\")\n",
    "print(f\"類別標籤對應：{train_dataset.class_to_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/speedlab-ml-1/anaconda3/envs/dann/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/speedlab-ml-1/anaconda3/envs/dann/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 加載 ResNet 模型，使用預訓練權重\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 替換最後一層全連接層\n",
    "num_ftrs = model.fc.in_features  # ResNet 最後一層的輸入特徵數量\n",
    "num_classes = len(train_dataset.classes)  # 六大類別\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)  # 替換為我們的輸出層\n",
    "\n",
    "# 將模型移至 GPU（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 定義損失函數（交叉熵損失）\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定義優化器（使用 Adam）\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 學習率調整器\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0784 Acc: 0.9734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0632 Acc: 0.9789\n",
      ">> Epoch 1: Validation accuracy improved to 0.9789, model saved to ./best_model.pth\n",
      "\n",
      "Epoch 2/3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0641 Acc: 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0584 Acc: 0.9803\n",
      ">> Epoch 2: Validation accuracy improved to 0.9803, model saved to ./best_model.pth\n",
      "\n",
      "Epoch 3/3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0613 Acc: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0569 Acc: 0.9808\n",
      ">> Epoch 3: Validation accuracy improved to 0.9808, model saved to ./best_model.pth\n",
      "\n",
      "訓練完成，耗時 13 分鐘 50 秒\n",
      "最佳驗證準確率：0.9808\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10, save_path='./best_model.pth'):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0  # 紀錄最佳準確率\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 40)\n",
    "\n",
    "        # 訓練與驗證\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 訓練模式\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()  # 驗證模式\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 使用 tqdm 顯示進度條\n",
    "            progress_bar = tqdm(dataloader, desc=f'{phase.capitalize()} Progress', leave=False)\n",
    "\n",
    "            for inputs, labels in progress_bar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()  # 反向傳播\n",
    "                        optimizer.step()  # 更新權重\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                # 更新進度條的描述\n",
    "                progress_bar.set_postfix(loss=f\"{running_loss / len(dataloader.dataset):.4f}\", acc=f\"{running_corrects.double() / len(dataloader.dataset):.4f}\")\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # 學習率調整\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # 保存最佳模型\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                print(f'>> Epoch {epoch + 1}: Validation accuracy improved to {best_acc:.4f}, model saved to {save_path}')\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\n訓練完成，耗時 {time_elapsed // 60:.0f} 分鐘 {time_elapsed % 60:.0f} 秒')\n",
    "    print(f'最佳驗證準確率：{best_acc:.4f}')\n",
    "    return model\n",
    "\n",
    "# 開始訓練\n",
    "trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=3)\n",
    "# torch.save(trained_model.state_dict(), 'resnet_classifier.pth')\n",
    "# print(\"模型權重已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CICIDS2017 類別數量: 6\n",
      "CICIDS2018 類別對應: {'Benign': 0, 'Botnets': 1, 'Brute-force': 2, 'DoS': 3, 'Web-attacks': 4}\n",
      "CICIDS2017 類別對應: {'Benign': 0, 'Botnets': 1, 'Brute-force': 2, 'DoS': 3, 'Port-scan': 4, 'Web-attacks': 5}\n"
     ]
    }
   ],
   "source": [
    "# 確保 CICIDS2018 目錄正確\n",
    "cicids2017_data_dir = \"data/image/cicids2017/train_224\"\n",
    "\n",
    "# 讀取測試數據\n",
    "cicids2017_dataset = datasets.ImageFolder(root=cicids2017_data_dir, transform=transform['val'])\n",
    "cicids2017_loader = DataLoader(cicids2017_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# 檢查類別標籤對應\n",
    "print(f\"CICIDS2017 類別數量: {len(cicids2017_dataset.classes)}\")\n",
    "print(f\"CICIDS2018 類別對應: {train_dataset.class_to_idx}\")\n",
    "print(f\"CICIDS2017 類別對應: {cicids2017_dataset.class_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標籤對應表 (將 CICIDS2018 的標籤對應回 CICIDS2017)\n",
    "label_mapping = {\n",
    "    0: 0,  # Benign -> Benign\n",
    "    1: 1,  # Botnets -> Botnets\n",
    "    2: 2,  # Brute-force -> Brute-force\n",
    "    3: 3,  # DoS -> DoS\n",
    "    4: 5,  # Port-scan (CICIDS2017:4) -> none\n",
    "    5: 4   # Web-attacks (CICIDS2017:5) -> 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 456/456 [00:10<00:00, 43.74batch/s, acc=0.4866, batch=456/456, processed=14592/14592]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CICIDS2018 測試集準確率: 0.4866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, dataloader, dataset, label_mapping):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 進度條初始化\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Evaluating\", unit=\"batch\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in pbar:\n",
    "            batch_size = images.size(0)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # 轉換測試標籤至訓練標籤對應\n",
    "            mapped_labels = torch.tensor([label_mapping[label.item()] for label in labels], device=device)\n",
    "\n",
    "            # 計算正確率\n",
    "            correct += (preds == mapped_labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # 更新進度條：顯示目前處理到第幾個 batch、圖片數、當前準確率\n",
    "            pbar.set_postfix(batch=f\"{batch_idx+1}/{len(dataloader)}\", processed=f\"{total}/{len(dataset)}\", acc=f\"{correct / total:.4f}\")\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"\\nCICIDS2018 測試集準確率: {acc:.4f}\")\n",
    "\n",
    "# 執行測試\n",
    "evaluate_model(trained_model, cicids2017_loader, cicids2017_dataset, label_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
